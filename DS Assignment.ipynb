{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1152e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duree</th>\n",
       "      <th>nbrtotc</th>\n",
       "      <th>chargtot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>163657.000000</td>\n",
       "      <td>163657.000000</td>\n",
       "      <td>1.636570e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.889786</td>\n",
       "      <td>0.123979</td>\n",
       "      <td>2.011004e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.244141</td>\n",
       "      <td>0.367597</td>\n",
       "      <td>5.885387e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.008219</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.989568e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               duree        nbrtotc      chargtot\n",
       "count  163657.000000  163657.000000  1.636570e+05\n",
       "mean        0.889786       0.123979  2.011004e+02\n",
       "std         0.244141       0.367597  5.885387e+03\n",
       "min         0.002740       0.000000  0.000000e+00\n",
       "25%         1.000000       0.000000  0.000000e+00\n",
       "50%         1.000000       0.000000  0.000000e+00\n",
       "75%         1.000000       0.000000  0.000000e+00\n",
       "max         1.008219       5.000000  1.989568e+06"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras \n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"Assignment.csv\")\n",
    "#df.head()\n",
    "\n",
    "#need to find out which features to removes\n",
    "\n",
    "features =df[]\n",
    "\n",
    "first_model = keras.models.Seqquential([\n",
    "    keras.layers.Dense(units = 64, activation = \"relu\", input_shape = [784])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5c24aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEPH</th>\n",
       "      <th>CODPOSS</th>\n",
       "      <th>duree</th>\n",
       "      <th>lnexpo</th>\n",
       "      <th>nbrtotc</th>\n",
       "      <th>nbrtotan</th>\n",
       "      <th>chargtot</th>\n",
       "      <th>agecar</th>\n",
       "      <th>sexp</th>\n",
       "      <th>fuelc</th>\n",
       "      <th>split</th>\n",
       "      <th>usec</th>\n",
       "      <th>fleetc</th>\n",
       "      <th>sportc</th>\n",
       "      <th>coverp</th>\n",
       "      <th>powerc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2-5</td>\n",
       "      <td>Female</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Once</td>\n",
       "      <td>Private</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>MTPL+</td>\n",
       "      <td>66-110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.046575</td>\n",
       "      <td>-3.066684</td>\n",
       "      <td>1</td>\n",
       "      <td>21.470588</td>\n",
       "      <td>155.974606</td>\n",
       "      <td>6-10</td>\n",
       "      <td>Female</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Twice</td>\n",
       "      <td>Private</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>MTPL</td>\n",
       "      <td>66-110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.402740</td>\n",
       "      <td>-0.909465</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&gt;10</td>\n",
       "      <td>Female</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Thrice</td>\n",
       "      <td>Private</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>MTPL</td>\n",
       "      <td>&lt;66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1030</td>\n",
       "      <td>0.169863</td>\n",
       "      <td>-1.772763</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2-5</td>\n",
       "      <td>Female</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Once</td>\n",
       "      <td>Professional</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>MTPL+++</td>\n",
       "      <td>66-110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>1030</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6-10</td>\n",
       "      <td>Female</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Once</td>\n",
       "      <td>Private</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>MTPL+</td>\n",
       "      <td>&lt;66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGEPH  CODPOSS     duree    lnexpo  nbrtotc   nbrtotan    chargtot agecar  \\\n",
       "0     64     1000  1.000000  0.000000        0   0.000000    0.000000    2-5   \n",
       "1     28     1000  0.046575 -3.066684        1  21.470588  155.974606   6-10   \n",
       "2     58     1000  0.402740 -0.909465        0   0.000000    0.000000    >10   \n",
       "3     37     1030  0.169863 -1.772763        0   0.000000    0.000000    2-5   \n",
       "4     29     1030  1.000000  0.000000        0   0.000000    0.000000   6-10   \n",
       "\n",
       "     sexp   fuelc   split          usec fleetc sportc   coverp  powerc  \n",
       "0  Female  Petrol    Once       Private     No     No    MTPL+  66-110  \n",
       "1  Female  Petrol   Twice       Private     No     No     MTPL  66-110  \n",
       "2  Female  Petrol  Thrice       Private     No     No     MTPL     <66  \n",
       "3  Female  Petrol    Once  Professional     No     No  MTPL+++  66-110  \n",
       "4  Female  Petrol    Once       Private     No     No    MTPL+     <66  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras \n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"Assignment.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aea2e0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "3676/3683 [============================>.] - ETA: 0s - loss: 42950.2344 - mean_absolute_error: 20.6684WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "3683/3683 [==============================] - 11s 3ms/step - loss: 42878.2617 - mean_absolute_error: 20.6608 - val_loss: 15547.5811 - val_mean_absolute_error: 19.2366\n",
      "Epoch 2/40\n",
      "3662/3683 [============================>.] - ETA: 0s - loss: 1399804.3750 - mean_absolute_error: 22.4926WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "3683/3683 [==============================] - 9s 3ms/step - loss: 1392106.5000 - mean_absolute_error: 22.3918 - val_loss: 46.5330 - val_mean_absolute_error: 3.0770\n",
      "Epoch 3/40\n",
      "3672/3683 [============================>.] - ETA: 0s - loss: 37811.8789 - mean_absolute_error: 14.9907WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "3683/3683 [==============================] - 9s 3ms/step - loss: 37707.9375 - mean_absolute_error: 14.9877 - val_loss: 1435.4188 - val_mean_absolute_error: 19.5825\n",
      "Epoch 4/40\n",
      "3674/3683 [============================>.] - ETA: 0s - loss: 30637.7891 - mean_absolute_error: 15.5521WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "3683/3683 [==============================] - 9s 3ms/step - loss: 30569.3906 - mean_absolute_error: 15.5294 - val_loss: 132.8178 - val_mean_absolute_error: 4.3435\n",
      "Epoch 5/40\n",
      "3670/3683 [============================>.] - ETA: 0s - loss: 505445.1250 - mean_absolute_error: 17.1277WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "3683/3683 [==============================] - 9s 3ms/step - loss: 503763.6562 - mean_absolute_error: 17.0729 - val_loss: 8.4393 - val_mean_absolute_error: 0.8948\n",
      "Epoch 6/40\n",
      "3683/3683 [==============================] - ETA: 0s - loss: 75310.7969 - mean_absolute_error: 9.9867WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "3683/3683 [==============================] - 9s 2ms/step - loss: 75310.7969 - mean_absolute_error: 9.9867 - val_loss: 331.2722 - val_mean_absolute_error: 12.5597\n",
      "Epoch 7/40\n",
      "3674/3683 [============================>.] - ETA: 0s - loss: 62236.8125 - mean_absolute_error: 28.1219WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "3683/3683 [==============================] - 9s 2ms/step - loss: 62097.9375 - mean_absolute_error: 28.0695 - val_loss: 287.9096 - val_mean_absolute_error: 6.1778\n",
      "Epoch 8/40\n",
      "3673/3683 [============================>.] - ETA: 0s - loss: 262221.0312 - mean_absolute_error: 29.6289WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "3683/3683 [==============================] - 9s 2ms/step - loss: 261562.5156 - mean_absolute_error: 29.5644 - val_loss: 128.2494 - val_mean_absolute_error: 3.6205\n",
      "Epoch 9/40\n",
      "3667/3683 [============================>.] - ETA: 0s - loss: 50520.8789 - mean_absolute_error: 12.3937WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "3683/3683 [==============================] - 9s 3ms/step - loss: 50311.9219 - mean_absolute_error: 12.3571 - val_loss: 82.0394 - val_mean_absolute_error: 3.2144\n",
      "Epoch 10/40\n",
      "3666/3683 [============================>.] - ETA: 0s - loss: 122312.3281 - mean_absolute_error: 11.0805WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "3683/3683 [==============================] - 9s 2ms/step - loss: 121773.3125 - mean_absolute_error: 11.0553 - val_loss: 246.9160 - val_mean_absolute_error: 6.3092\n",
      "Epoch 11/40\n",
      "3666/3683 [============================>.] - ETA: 0s - loss: 112911.9844 - mean_absolute_error: 8.8215WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "3683/3683 [==============================] - 10s 3ms/step - loss: 112414.4844 - mean_absolute_error: 8.8328 - val_loss: 475.3061 - val_mean_absolute_error: 6.2130\n",
      "Epoch 12/40\n",
      "3679/3683 [============================>.] - ETA: 0s - loss: 56864.4531 - mean_absolute_error: 8.9335WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "3683/3683 [==============================] - 10s 3ms/step - loss: 56814.2656 - mean_absolute_error: 8.9269 - val_loss: 14.1351 - val_mean_absolute_error: 1.3872\n",
      "Epoch 13/40\n",
      "2676/3683 [====================>.........] - ETA: 2s - loss: 396.5885 - mean_absolute_error: 2.2072"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#Split the data\u001b[39;00m\n\u001b[0;32m     37\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_encoded\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mduree\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"Assignment.csv\")\n",
    "\n",
    "#do one hot encoding for catagorical features \n",
    "df_encoded = pd.get_dummies(df, columns = ['agecar', 'sexp', 'fuelc', 'split', 'usec', 'fleetc','sportc', 'coverp', 'powerc'])\n",
    "\n",
    "df_features = []\n",
    "\n",
    "for col in df_encoded.columns:\n",
    "    if col != \"nbrtotan\":\n",
    "        df_features.append(col)\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(units = 64, activation = 'relu', input_shape=(len(df_features),)),\n",
    "    keras.layers.Dense(32, activation = 'relu' ),\n",
    "    keras.layers.Dense(1, activation = 'linear')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'mse',\n",
    "              metrics = ['mean_absolute_error']\n",
    ")\n",
    "\n",
    "#Prepare features and labels \n",
    "X = df_encoded[df_features]\n",
    "y = df_encoded['nbrtotan']\n",
    "\n",
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=40, sample_weight =df_encoded['duree'],  batch_size=32, validation_split=0.1)\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss Over Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b414351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/24/ec/ad387100fa3cc2b9b81af0829b5ecfe75ec5bb19dd7c19d4fea06fb81802/xgboost-2.0.3-py3-none-win_amd64.whl.metadata\n",
      "  Downloading xgboost-2.0.3-py3-none-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\jaspe\\anaconda3\\lib\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\jaspe\\anaconda3\\lib\\site-packages (from xgboost) (1.10.1)\n",
      "Downloading xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n",
      "   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.4/99.8 MB 8.7 MB/s eta 0:00:12\n",
      "   ---------------------------------------- 0.4/99.8 MB 8.7 MB/s eta 0:00:12\n",
      "   ---------------------------------------- 1.2/99.8 MB 6.8 MB/s eta 0:00:15\n",
      "    --------------------------------------- 1.8/99.8 MB 8.3 MB/s eta 0:00:12\n",
      "    --------------------------------------- 2.4/99.8 MB 8.8 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 3.0/99.8 MB 9.4 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 3.8/99.8 MB 10.0 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 4.3/99.8 MB 10.2 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 4.9/99.8 MB 10.5 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 5.5/99.8 MB 10.7 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 6.2/99.8 MB 11.0 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 6.9/99.8 MB 11.4 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 7.0/99.8 MB 11.5 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 7.0/99.8 MB 11.5 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 7.0/99.8 MB 11.5 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 7.0/99.8 MB 11.5 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 7.0/99.8 MB 11.5 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 7.0/99.8 MB 11.5 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 7.5/99.8 MB 7.9 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 8.1/99.8 MB 8.2 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 8.7/99.8 MB 8.5 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 9.5/99.8 MB 8.9 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 9.9/99.8 MB 8.9 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 10.6/99.8 MB 9.1 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 11.5/99.8 MB 9.9 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 12.2/99.8 MB 9.9 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 12.9/99.8 MB 10.2 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 13.6/99.8 MB 10.2 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 14.3/99.8 MB 10.2 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 15.2/99.8 MB 10.6 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 16.1/99.8 MB 10.7 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 17.2/99.8 MB 10.7 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 17.5/99.8 MB 15.6 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 17.9/99.8 MB 13.9 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 19.0/99.8 MB 14.5 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 19.8/99.8 MB 14.6 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 20.8/99.8 MB 14.9 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 21.8/99.8 MB 14.6 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 22.8/99.8 MB 14.5 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 23.7/99.8 MB 14.6 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 24.7/99.8 MB 14.5 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 25.4/99.8 MB 14.6 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 26.2/99.8 MB 14.2 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 26.9/99.8 MB 13.9 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 27.5/99.8 MB 14.2 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 27.5/99.8 MB 14.2 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 27.9/99.8 MB 13.6 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 28.6/99.8 MB 13.6 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 29.2/99.8 MB 13.4 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 29.9/99.8 MB 13.6 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 30.6/99.8 MB 13.4 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 31.3/99.8 MB 13.4 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 32.0/99.8 MB 13.6 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 32.8/99.8 MB 13.4 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 33.6/99.8 MB 13.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 34.4/99.8 MB 13.6 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 35.2/99.8 MB 13.6 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 35.8/99.8 MB 14.2 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 36.5/99.8 MB 13.9 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 37.2/99.8 MB 13.9 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 38.0/99.8 MB 15.6 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 39.0/99.8 MB 15.6 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 40.0/99.8 MB 15.6 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 41.0/99.8 MB 15.6 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 41.5/99.8 MB 15.6 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 41.5/99.8 MB 15.6 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 42.1/99.8 MB 13.9 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 43.0/99.8 MB 13.9 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 43.9/99.8 MB 13.6 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 44.6/99.8 MB 13.4 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 45.3/99.8 MB 13.4 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 45.8/99.8 MB 13.4 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 46.6/99.8 MB 13.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 47.1/99.8 MB 13.6 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 47.8/99.8 MB 13.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 48.4/99.8 MB 13.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 48.9/99.8 MB 12.9 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 49.6/99.8 MB 13.1 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 50.2/99.8 MB 12.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 50.9/99.8 MB 12.9 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 51.6/99.8 MB 12.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 52.4/99.8 MB 14.2 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 53.0/99.8 MB 14.2 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 53.8/99.8 MB 13.9 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 54.8/99.8 MB 14.2 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 55.8/99.8 MB 14.5 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 56.6/99.8 MB 14.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 57.6/99.8 MB 14.9 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 58.5/99.8 MB 14.6 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 59.3/99.8 MB 14.9 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 60.3/99.8 MB 15.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 60.8/99.8 MB 15.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 61.5/99.8 MB 14.9 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 62.3/99.8 MB 14.9 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 63.1/99.8 MB 15.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 64.2/99.8 MB 15.6 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 65.1/99.8 MB 15.6 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 65.9/99.8 MB 15.6 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 66.6/99.8 MB 15.6 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 67.3/99.8 MB 15.6 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 68.1/99.8 MB 16.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 68.8/99.8 MB 15.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 69.6/99.8 MB 15.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 70.3/99.8 MB 15.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 71.1/99.8 MB 16.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 71.8/99.8 MB 16.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 72.5/99.8 MB 16.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 73.2/99.8 MB 16.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 73.8/99.8 MB 15.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 74.5/99.8 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 75.2/99.8 MB 14.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 76.0/99.8 MB 14.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 76.5/99.8 MB 14.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 77.0/99.8 MB 13.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 77.7/99.8 MB 13.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 78.4/99.8 MB 12.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 79.3/99.8 MB 12.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 80.0/99.8 MB 12.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 80.6/99.8 MB 12.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 81.1/99.8 MB 12.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 81.8/99.8 MB 12.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 82.5/99.8 MB 12.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 83.1/99.8 MB 12.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 83.6/99.8 MB 12.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 84.3/99.8 MB 12.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 85.0/99.8 MB 12.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 85.3/99.8 MB 12.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 85.5/99.8 MB 11.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 86.1/99.8 MB 11.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 86.8/99.8 MB 11.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 87.4/99.8 MB 12.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 88.0/99.8 MB 12.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 88.8/99.8 MB 13.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 89.6/99.8 MB 12.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 90.0/99.8 MB 12.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 90.6/99.8 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 91.2/99.8 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 92.0/99.8 MB 12.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 92.6/99.8 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 93.4/99.8 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 94.2/99.8 MB 12.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 94.9/99.8 MB 12.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 95.9/99.8 MB 13.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 97.0/99.8 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  98.0/99.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  98.9/99.8 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 99.8/99.8 MB 5.9 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c497240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023/1023 [==============================] - 2s 2ms/step\n",
      "Mean Absolute Error (MAE): 0.27469037144008907\n",
      "Mean Squared Error (MSE): 0.9500314298160848\n",
      "R-squared: -4.332572055831818e-05\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Flatten predictions if necessary\n",
    "predictions = predictions.flatten()\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce0ebd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AGEPH' 'CODPOSS' 'duree' 'lnexpo' 'nbrtotc' 'nbrtotan' 'chargtot'\n",
      " 'agecar' 'sexp' 'fuelc' 'split' 'usec' 'fleetc' 'sportc' 'coverp'\n",
      " 'powerc']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e4e5e20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaspe\\AppData\\Local\\Temp\\ipykernel_5072\\3502351144.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = le.fit_transform(data[col])\n",
      "C:\\Users\\jaspe\\AppData\\Local\\Temp\\ipykernel_5072\\3502351144.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = le.fit_transform(data[col])\n",
      "C:\\Users\\jaspe\\AppData\\Local\\Temp\\ipykernel_5072\\3502351144.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = le.fit_transform(data[col])\n",
      "C:\\Users\\jaspe\\AppData\\Local\\Temp\\ipykernel_5072\\3502351144.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = le.fit_transform(data[col])\n",
      "C:\\Users\\jaspe\\AppData\\Local\\Temp\\ipykernel_5072\\3502351144.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = le.fit_transform(data[col])\n",
      "C:\\Users\\jaspe\\AppData\\Local\\Temp\\ipykernel_5072\\3502351144.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = le.fit_transform(data[col])\n",
      "C:\\Users\\jaspe\\AppData\\Local\\Temp\\ipykernel_5072\\3502351144.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = le.fit_transform(data[col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation RMSE: 0.8801756609081866\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Assuming df is your DataFrame already loaded with necessary data\n",
    "data_cols = ['agecar', 'fuelc', 'usec', 'fleetc', 'sportc', 'coverp', 'powerc'] \n",
    "data = df[['AGEPH', 'agecar', 'fuelc', 'usec', 'fleetc', 'sportc', 'coverp', 'powerc']]\n",
    "freq = df['nbrtotan']\n",
    "\n",
    "# Option to choose encoding type: 'label' or 'one-hot'\n",
    "encoding_type = 'label'  # Change to 'one-hot' as needed\n",
    "\n",
    "if encoding_type == 'label':\n",
    "    # Label Encoding\n",
    "    le = LabelEncoder()\n",
    "    for col in data_cols:\n",
    "        data[col] = le.fit_transform(data[col])\n",
    "else:\n",
    "    # One-Hot Encoding\n",
    "    data = pd.get_dummies(data, columns=data_cols)\n",
    "    # Clean up column names to avoid issues with special characters\n",
    "    data.columns = [\"\".join(c if c.isalnum() else \"_\" for c in str(x)) for x in data.columns]\n",
    "\n",
    "X = data\n",
    "y = freq  # Directly using the freq column from original dataframe\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.01,\n",
    "    subsample=0.8,\n",
    "    max_depth=5,\n",
    "    colsample_bytree=0.6,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.2\n",
    ")\n",
    "\n",
    "# Run cross-validation\n",
    "scores = cross_val_score(\n",
    "    model, \n",
    "    X_train, \n",
    "    y_train, \n",
    "    cv=15,  # number of folds\n",
    "    scoring='neg_root_mean_squared_error'\n",
    ")\n",
    "\n",
    "print(\"Cross-validation RMSE:\", np.mean(np.abs(scores)))\n",
    "\n",
    "# # Randomized Search to find the best hyperparameters\n",
    "# random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=25, scoring='neg_mean_squared_error', error_score=0, verbose=3, n_jobs=-1, cv=3)\n",
    "# random_search.fit(X_train, y_train)\n",
    "# print(f\"Best parameters found: {random_search.best_params_}\")\n",
    "\n",
    "# # Using the best estimator found\n",
    "# model = random_search.best_estimator_\n",
    "# y_pred = model.predict(X_test)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# print(f\"Optimized RMSE with {encoding_type} encoding: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f43d251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
